"""
replace_archived_video_files.py

This module processes a CSV report of video file conversions and moves, typically generated by a video processing pipeline. It provides the following features:

- Calculates and reports the total and per-file sizes of original and converted video files.
- Optionally overwrites the original video files with their converted versions, using the converted file's extension.
- Optionally backs up the original files to a failsafe archive folder before overwriting, with unique naming to avoid conflicts.
- Tracks the location of each failsafe backup in the output report.
- Removes the original file before copying the converted file back, ensuring no coexistence of old and new files.
- Outputs a detailed CSV report (excluding 'skip' actions) with all relevant file paths, sizes, and backup locations.

Configuration options at the top of the script control input/output paths, overwrite and failsafe behavior, and CSV formatting.

Typical usage: Run this script after a batch video conversion to finalize the archive, optionally replace originals, and generate a comprehensive report for auditing and rollback.
"""

import os
import pandas as pd
import shutil
import random
import string

# Configuration
INPUT_CSV_FOLDER_PATH = "report/2024"
INPUT_CSV_FILE_NAME = "icloud_video_report_processed.csv"
CSV_SEPARATOR = ";"
OVERWRITE_ORIGINAL_FILE = True  # Set to True to overwrite original file with converted file
STORE_ORIGINAL_IN_FAILSAFE = True  # Set to True to store original in failsafe before overwrite
FAILSAFE_FOLDER_PATH = "data/archive_failsafe"
OUTPUT_CSV_FOLDER_PATH = "report/2024"
OUTPUT_CSV_FILE_NAME = "replace_archive_video_report.csv"


def human_readable_size(size_bytes):
    if size_bytes == 0:
        return "0B"
    size_name = ("B", "KB", "MB", "GB", "TB")
    i = 0
    p = 1024
    while size_bytes >= p and i < len(size_name) - 1:
        size_bytes /= p
        i += 1
    return f"{size_bytes:.2f} {size_name[i]}"


def main():
    input_csv_path = os.path.join(INPUT_CSV_FOLDER_PATH, INPUT_CSV_FILE_NAME)
    dtype_schema = {
        'action': str,
        'processing_status': str,
        'file': str,
        'derived_file': str
    }
    df = pd.read_csv(input_csv_path, sep=CSV_SEPARATOR, dtype=dtype_schema)
    df = df.fillna('')  # Ensure all missing values are empty strings

    # Add columns for file sizes
    df['source_file_size'] = 0
    df['converted_file_size'] = 0
    df['failsafe_backup_path'] = ''
    os.makedirs(FAILSAFE_FOLDER_PATH, exist_ok=True)

    for idx, row in df.iterrows():
        action = (row.get('action') or '').strip().lower()
        status = (row.get('processing_status') or '').strip().upper()
        if action in ('convert', 'move') and status == 'SUCCESS':
            src = (row.get('file') or '').strip()
            dst = (row.get('derived_file') or '').strip()
            src_size = os.path.getsize(src) if os.path.exists(src) else 0
            dst_size = os.path.getsize(dst) if os.path.exists(dst) else 0
            df.at[idx, 'source_file_size'] = src_size
            df.at[idx, 'converted_file_size'] = dst_size

            # Overwrite original file for converted videos if flag is set
            if OVERWRITE_ORIGINAL_FILE and action == 'convert' and os.path.exists(dst):
                orig_dir = os.path.dirname(src)
                orig_stem = os.path.splitext(os.path.basename(src))[0]
                dst_ext = os.path.splitext(dst)[1]
                overwrite_path = os.path.join(orig_dir, orig_stem + dst_ext)
                failsafe_path = ''
                # If enabled, backup original to failsafe before removal
                if STORE_ORIGINAL_IN_FAILSAFE and os.path.exists(src):
                    failsafe_base = os.path.basename(src)
                    failsafe_path = os.path.join(FAILSAFE_FOLDER_PATH, failsafe_base)
                    # Handle name conflict by adding random 3-letter suffix
                    while os.path.exists(failsafe_path):
                        suffix = ''.join(random.choices(string.ascii_lowercase, k=3))
                        base, ext = os.path.splitext(failsafe_base)
                        failsafe_path = os.path.join(FAILSAFE_FOLDER_PATH, f"{base}_{suffix}{ext}")
                    try:
                        shutil.copy2(src, failsafe_path)
                        print(f"Backed up original file to failsafe: {failsafe_path}")
                        df.at[idx, 'failsafe_backup_path'] = failsafe_path
                    except Exception as e:
                        print(f"Failed to backup original to failsafe: {e}")
                # Always remove the original file before copying back the converted one
                if os.path.exists(src):
                    try:
                        os.remove(src)
                        print(f"Removed original file before overwrite: {src}")
                    except Exception as e:
                        print(f"Failed to remove original file before overwrite: {e}")
                try:
                    shutil.copy2(dst, overwrite_path)
                    print(f"Overwrote original file: {overwrite_path} with converted file: {dst}")
                except Exception as e:
                    print(f"Failed to overwrite {overwrite_path} with {dst}: {e}")

    # Filter for successfully converted files only
    converted_df = df[(df['action'].str.lower() == 'convert') & (df['processing_status'].str.upper() == 'SUCCESS')].copy()
    converted_df['size_delta'] = converted_df['source_file_size'] - converted_df['converted_file_size']
    converted_df = converted_df.sort_values(by='size_delta', ascending=False)

    # Set pandas display options for better console output
    pd.set_option('display.max_rows', 100)
    pd.set_option('display.max_columns', 10)
    pd.set_option('display.width', 200)
    pd.set_option('display.colheader_justify', 'left')
    pd.set_option('display.float_format', '{:,.0f}'.format)
    pd.set_option('display.max_colwidth', None)  # Show full file paths

    print(converted_df[['file', 'derived_file', 'action', 'source_file_size', 'converted_file_size', 'size_delta']])

    total_source_size = converted_df['source_file_size'].sum()
    total_converted_size = converted_df['converted_file_size'].sum()
    count = len(converted_df)
    print(f"Total source file size for {count} converted files: {total_source_size} bytes ({human_readable_size(total_source_size)})")
    print(f"Total converted file size for {count} converted files: {total_converted_size} bytes ({human_readable_size(total_converted_size)})")

    # Write the DataFrame to the report section as well, but exclude all 'skip' actions
    df_no_skip = df[df['action'].str.lower() != 'skip'].copy()
    os.makedirs(OUTPUT_CSV_FOLDER_PATH, exist_ok=True)
    output_csv_path = os.path.join(OUTPUT_CSV_FOLDER_PATH, OUTPUT_CSV_FILE_NAME)
    df_no_skip.to_csv(output_csv_path, sep=CSV_SEPARATOR, index=False)
    print(f"Wrote detailed report to {output_csv_path} (excluding 'skip' actions)")


if __name__ == "__main__":
    main()
